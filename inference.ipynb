{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4d96ed2-a7b9-4c12-9106-6fce4a0178c5",
   "metadata": {},
   "source": [
    "# Inference Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2802832d-8b42-46d3-ae0f-7974fd373c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import TMPipeline\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bfef86-3f9a-4c2a-bef0-904786984c9b",
   "metadata": {},
   "source": [
    "## Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d96f42-f254-4a11-973c-b112979b3be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['BBC_News', 'Arxiv_Abstracts', 'ChatGPT_Tweets']\n",
    "vectorizers = ['tf', 'tfidf']\n",
    "models = ['lda', 'nmf', 'kmeans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a6ead3-4c17-4e50-8717-23e728b86d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    for vectorizer in vectorizers:\n",
    "        for model in models:\n",
    "            pipeline = 'TTM'\n",
    "            \n",
    "            if model == 'kmeans':\n",
    "                pipeline = 'LLM'\n",
    "\n",
    "            runs.append([dataset, pipeline, vectorizer, model])\n",
    "\n",
    "print(len(runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b77076-68e6-45ae-9908-6bc109298dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in runs:\n",
    "    data = os.path.join('Data/Datasets/Original/', run[0], run[1], run[0] +'.txt')\n",
    "    tm_pipeline = TMPipeline(data, run[1])\n",
    "    tm_pipeline.preprocess()\n",
    "    tm_pipeline.vectorize(run[2])\n",
    "    tm_pipeline.optimize(run[3], 10, 50, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d747ab-c2a0-4799-b72a-cc1ec5dce802",
   "metadata": {},
   "source": [
    "## Single Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184360af-7eed-4db6-94a4-01d1359f4731",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= 'ChatGPT_Tweets'\n",
    "pipeline = 'TTM'\n",
    "vectorizer = 'tfidf'\n",
    "model = 'lda'\n",
    "\n",
    "data = os.path.join('Data/Datasets/Processed', dataset, pipeline, dataset +'.txt')\n",
    "tm_pipeline = TMPipeline(data, pipeline)\n",
    "tm_pipeline.preprocess()\n",
    "tm_pipeline.vectorize(vectorizer)\n",
    "tm_pipeline.model_topics(model, 10)\n",
    "tm_pipeline.results(save=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
